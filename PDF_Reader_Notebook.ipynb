{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pip install langchain\n",
    "pip install openai\n",
    "pip install PyPDF2\n",
    "pip install faiss-cpu\n",
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate, FAISS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e68571271723ed1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# connect your Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "root_dir = \"/content/gdrive/My Drive/\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "162742593c1c673b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# location of the pdf file/files. \n",
    "reader = PdfReader('/content/gdrive/My Drive/data/2023_GPT4All_Technical_Report.pdf')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4aee49f7fb1fb212"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reader"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a1bbbbbff6a38d0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read data from the file and put them into a variable called raw_text\n",
    "raw_text = ''\n",
    "for i, page in enumerate(reader.pages):\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        raw_text += text"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5618f5be18113ae2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# raw_text"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fe1d99b3bbbd651"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw_text[:100]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8bb0d716896aa90"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We need to split the text that we read into smaller chunks so that during information retreival we don't hit the token size limits. \n",
    "\n",
    "text_splitter = CharacterTextSplitter(        \n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    ")\n",
    "texts = text_splitter.split_text(raw_text)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b6756320187c858"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(texts)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25eef7a3a5539878"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "texts[0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9953105808896b8e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "texts[1]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55e6bc121fa11c83"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Download embeddings from OpenAI\n",
    "embeddings = OpenAIEmbeddings()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b2f144553018a02"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "docsearch = FAISS.from_texts(texts, embeddings)\n",
    "docsearch"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "547fbc164bac26bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb19044b6ab340fb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd57eb21bbbb3991"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = \"who are the authors of the article?\"\n",
    "docs = docsearch.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "591491dd6de8da5d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = \"What was the cost of training the GPT4all model?\"\n",
    "docs = docsearch.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75ca590391cb9c21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = \"How was the model trained?\"\n",
    "docs = docsearch.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9415f44a39a34981"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = \"what was the size of the training dataset?\"\n",
    "docs = docsearch.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83629601035b28f0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = \"How is this different from other models?\"\n",
    "docs = docsearch.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56c1c1540678a8db"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = \"What is Google Bard?\"\n",
    "docs = docsearch.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15f178766f66d0b0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
